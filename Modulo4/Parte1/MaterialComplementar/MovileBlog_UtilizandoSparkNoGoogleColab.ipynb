{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovileBlog_UtilizandoSparkNoGoogleColab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlfYT81y6ULf",
        "colab_type": "text"
      },
      "source": [
        "# Apache Spark: o que é e como utilizá-lo com o Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ilOjw46bBg",
        "colab_type": "text"
      },
      "source": [
        "### Instalação e configuração das bibliotecas e suas dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2mOzuDzS2X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baixando e instalando o Java (JDK)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null #Java\n",
        "\n",
        "# Baixando e instalando o ecossistema Hadoop com o Spark\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7-hive1.2.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7-hive1.2.tgz\n",
        "\n",
        "# Importando as bibliotecas Python para executar o Spark\n",
        "!pip install -q findspark\n",
        "!pip install -q pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLhAHbxp6owm",
        "colab_type": "text"
      },
      "source": [
        "### Exploração das estruturas de pastas criadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e26ysTxD3Auj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8a73e71-ef8e-4f89-8808-6a7b366adaeb"
      },
      "source": [
        "# Java\n",
        "!ls /usr/lib/jvm/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdphmLRI2zU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f4063fce-3992-42b7-8572-eced519c2f5c"
      },
      "source": [
        "# Spark\n",
        "!ls /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t\t       spark-3.0.1-bin-hadoop2.7-hive1.2.tgz.1\n",
            "spark-3.0.1-bin-hadoop2.7-hive1.2      spark-3.0.1-bin-hadoop2.7-hive1.2.tgz.2\n",
            "spark-3.0.1-bin-hadoop2.7-hive1.2.tgz  spark-3.0.1-bin-hadoop2.7-hive1.2.tgz.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPRguT3v7fJb",
        "colab_type": "text"
      },
      "source": [
        "### Criação das variáveis de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVOWRN5n2T6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7-hive1.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flr1wYMK7klj",
        "colab_type": "text"
      },
      "source": [
        "### Inicialização do Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLYW7i1k2tbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C-Go_YD7oaT",
        "colab_type": "text"
      },
      "source": [
        "### Inicialização de uma sessão no Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnJ5hag23Uyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF7yrQmi3evD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "624776c1-bc3f-4f1a-e90d-4bad4edc8583"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8c07e28a8edd:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f250ccb0c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb5pdBEy7xVq",
        "colab_type": "text"
      },
      "source": [
        "### Exploração do conjunto de dados Anscombe (um dos exemplos no Google Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDzc5FaG8vYV",
        "colab_type": "text"
      },
      "source": [
        "Quarteto de Anscombe é o nome dado a quatro conjuntos de dados que têm estatísticas descritivas quase idênticas (como a média e a variância), mas que têm distribuições muito diferentes e aparências muito distintas quando exibidos graficamente. Cada conjunto de dados consiste de onze pontos (x,y). Eles foram construídos em 1973 pelo estatístico Francis Anscombe, com o objetivo de demonstrar tanto a importância de se visualizar os dados antes de analisá-los, quanto o efeito dos outliers e outras observações influentes nas propriedades estatísticas. Ele descreveu o artigo como tendo a finalidade de combater a impressão entre os estatísticos de que \"cálculos numéricos são exatos, mas gráficos são aproximados/grosseiros.\"\n",
        "\n",
        "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ec/Anscombe%27s_quartet_3.svg\" width=\"800\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3KigTeZ4jfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8c3f12f-4e67-40a4-bc09-cd5df61c1f9f"
      },
      "source": [
        "# Lendo o conjunto de dados\n",
        "dataset = spark.read.format(\"json\").option(\"multiLine\", True).load(\"sample_data/anscombe.json\")\n",
        "\n",
        "# Apresentando as colunas\n",
        "dataset.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Series', 'X', 'Y']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHdkoh9J49-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "89052286-1f6e-44fc-e18a-a84434a97368"
      },
      "source": [
        "# Apresentando os primeiros 10 registros do conjunto de dados \n",
        "dataset.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+\n",
            "|Series|   X|    Y|\n",
            "+------+----+-----+\n",
            "|     I|10.0| 8.04|\n",
            "|     I| 8.0| 6.95|\n",
            "|     I|13.0| 7.58|\n",
            "|     I| 9.0| 8.81|\n",
            "|     I|11.0| 8.33|\n",
            "|     I|14.0| 9.96|\n",
            "|     I| 6.0| 7.24|\n",
            "|     I| 4.0| 4.26|\n",
            "|     I|12.0|10.84|\n",
            "|     I| 7.0| 4.81|\n",
            "+------+----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsE8eJfw5JvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ff3026a9-c4e3-454f-81c8-db39d737b815"
      },
      "source": [
        "# Apresentando o schema (tipos das variáveis) inferido pelo Spark\n",
        "dataset.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Series: string (nullable = true)\n",
            " |-- X: double (nullable = true)\n",
            " |-- Y: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACb1aQHL5Qkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "564462b7-4563-473e-f918-e4effac2722c"
      },
      "source": [
        "# Importando a biblioteca de funções SQL do Spark\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Agrupando os dados pelo tipo de conjunto, calculando os valores aggregados (médias) de X e Y e ordenando pelo tipo de conjunto\n",
        "dataset_agrupado = dataset.groupBy(\"Series\") \\\n",
        "                          .agg(F.avg(\"X\").alias(\"X_agrupado\"), F.avg(\"Y\").alias(\"Y_agrupado\"))  \\\n",
        "                          .orderBy(\"Series\")\n",
        "\n",
        "# Apresentando o resultado do agrupamento\n",
        "dataset_agrupado.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----------+-----------------+\n",
            "|Series|X_agrupado|       Y_agrupado|\n",
            "+------+----------+-----------------+\n",
            "|     I|       9.0|              7.5|\n",
            "|    II|       9.0|7.500909090909091|\n",
            "|   III|       9.0|7.500000000000001|\n",
            "|    IV|       9.0| 7.50090909090909|\n",
            "+------+----------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hvm3T9M5qY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "46d2a3aa-6256-44f3-90b0-b0b5342bba0a"
      },
      "source": [
        "# Explicação do plano de execução do Spark\n",
        "dataset_agrupado.explain()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== Physical Plan ==\n",
            "*(3) Sort [Series#0 ASC NULLS FIRST], true, 0\n",
            "+- Exchange rangepartitioning(Series#0 ASC NULLS FIRST, 200), true, [id=#62]\n",
            "   +- *(2) HashAggregate(keys=[Series#0], functions=[avg(X#1), avg(Y#2)])\n",
            "      +- Exchange hashpartitioning(Series#0, 200), true, [id=#58]\n",
            "         +- *(1) HashAggregate(keys=[Series#0], functions=[partial_avg(X#1), partial_avg(Y#2)])\n",
            "            +- FileScan json [Series#0,X#1,Y#2] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex[file:/content/sample_data/anscombe.json], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Series:string,X:double,Y:double>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VNHs6z3_2mu",
        "colab_type": "text"
      },
      "source": [
        "### Referências:\n",
        "\n",
        "https://movile.blog/introducao-a-spark-usando-o-google-colab/\n",
        "\n",
        "https://pt.wikipedia.org/wiki/Quarteto_de_Anscombe"
      ]
    }
  ]
}